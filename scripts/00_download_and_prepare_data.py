#!/usr/bin/env python3
"""
–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ NIH ChestX-ray –¥–∞—Ç–∞—Å–µ—Ç–∞
"""

import os
import pandas as pd
import requests
import zipfile
from tqdm import tqdm
import numpy as np

class NIHDataPreparer:
    def __init__(self, data_dir="./data"):
        self.data_dir = data_dir
        self.images_dir = os.path.join(data_dir, "images")
        self.labels_dir = os.path.join(data_dir, "labels")
        os.makedirs(self.images_dir, exist_ok=True)
        os.makedirs(self.labels_dir, exist_ok=True)
    
    def download_nih_dataset(self):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ NIH ChestX-ray –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print("üì• –°–∫–∞—á–∏–≤–∞–µ–º NIH ChestX-ray –¥–∞—Ç–∞—Å–µ—Ç...")
        
        # URLs –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–ø—Ä–∏–º–µ—Ä - –Ω—É–∂–Ω–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ)
        nih_urls = [
            "https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz",
            # –î–æ–±–∞–≤—å—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
        ]
        
        for i, url in enumerate(nih_urls):
            filename = f"images_{i+1:02d}.gz"
            filepath = os.path.join(self.images_dir, filename)
            
            if not os.path.exists(filepath):
                print(f"–°–∫–∞—á–∏–≤–∞–µ–º {filename}...")
                # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
                self._download_file(url, filepath)
    
    def _download_file(self, url, filepath):
        """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º"""
        response = requests.get(url, stream=True)
        total_size = int(response.headers.get('content-length', 0))
        
        with open(filepath, 'wb') as file, tqdm(
            desc=os.path.basename(filepath),
            total=total_size,
            unit='iB',
            unit_scale=True,
            unit_divisor=1024,
        ) as bar:
            for data in response.iter_content(chunk_size=1024):
                size = file.write(data)
                bar.update(size)
    
    def load_and_filter_metadata(self, csv_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        print("üìä –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ...")
        
        df = pd.read_csv(csv_path)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å–Ω–∏–º–∫–∏
        normal_images = df[df['Finding Labels'] == 'No Finding']
        
        print(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ NIH:")
        print(f"   –í—Å–µ–≥–æ —Å–Ω–∏–º–∫–æ–≤: {len(df)}")
        print(f"   –ù–æ—Ä–º–∞–ª—å–Ω—ã—Ö —Å–Ω–∏–º–∫–æ–≤: {len(normal_images)}")
        print(f"   –° –ø–∞—Ç–æ–ª–æ–≥–∏—è–º–∏: {len(df) - len(normal_images)}")
        
        return df, normal_images
    
    def create_balanced_dataset(self, normal_images, clavicle_images, foreign_body_images):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º"""
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        target_counts = {
            'normal': 250,        # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å
            'clavicle_fracture': 125,
            'foreign_body_bronchus': 85
        }
        
        print("üéØ –°–æ–∑–¥–∞–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç:")
        print(f"   –ù–æ—Ä–º–∞: {target_counts['normal']} —Å–Ω–∏–º–∫–æ–≤")
        print(f"   –ü–µ—Ä–µ–ª–æ–º—ã –∫–ª—é—á–∏—Ü—ã: {target_counts['clavicle_fracture']} —Å–Ω–∏–º–∫–æ–≤")
        print(f"   –ò–Ω–æ—Ä–æ–¥–Ω—ã–µ —Ç–µ–ª–∞: {target_counts['foreign_body_bronchus']} —Å–Ω–∏–º–∫–æ–≤")
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Å–Ω–∏–º–∫–∏ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
        selected_normal = normal_images.sample(
            n=min(target_counts['normal'], len(normal_images)),
            random_state=42
        )
        
        # –î–ª—è –ø–∞—Ç–æ–ª–æ–≥–∏–π –±–µ—Ä–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ (–∏–ª–∏ –¥–æ —Ü–µ–ª–µ–≤–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞)
        selected_clavicle = clavicle_images[:target_counts['clavicle_fracture']]
        selected_foreign_body = foreign_body_images[:target_counts['foreign_body_bronchus']]
        
        return selected_normal, selected_clavicle, selected_foreign_body
    
    def prepare_yolo_structure(self, train_ratio=0.7, val_ratio=0.15):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫ –≤ YOLO —Ñ–æ—Ä–º–∞—Ç–µ"""
        
        splits = {
            'train': train_ratio,
            'val': val_ratio,
            'test': 1 - train_ratio - val_ratio
        }
        
        for split in splits.keys():
            os.makedirs(os.path.join(self.images_dir, split), exist_ok=True)
            os.makedirs(os.path.join(self.labels_dir, split), exist_ok=True)
        
        print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ YOLO —Å–æ–∑–¥–∞–Ω–∞")
        return splits

def main():
    preparer = NIHDataPreparer()
    
    # 1. –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    # preparer.download_nih_dataset()
    
    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    try:
        df, normal_images = preparer.load_and_filter_metadata("Data_Entry_2017.csv")
        
        # 3. –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ —Å –ø–∞—Ç–æ–ª–æ–≥–∏—è–º–∏
        # clavicle_images = load_your_clavicle_data()
        # foreign_body_images = load_your_foreign_body_data()
        
        # 4. –°–æ–∑–¥–∞–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        # balanced_data = preparer.create_balanced_dataset(
        #     normal_images, clavicle_images, foreign_body_images
        # )
        
        # 5. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        preparer.prepare_yolo_structure()
        
        print("üéâ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        print("üí° –°–∫–∞—á–∞–π—Ç–µ Data_Entry_2017.csv —Å https://nihcc.app.box.com/v/ChestXray-NIHCC")

if __name__ == "__main__":
    main()
